---
title: "CMSC 320 Final Project"
author: "Ryan Brown, Collin Brown"
output: html_document
---

This tutorial will be a walkthrough of the data science pipeline. First, we will scrape data from a website, clean it and format it in a way we can better use it. We will then do some exploratory data analysis involving both standardization and regressions.


The dataset we will be using for this tutorial is player statistics from the North American League of Legends Championship Series. 

![](/Users/blue/Downloads/lcs.jpg)

A little background: the North American League of Legends Championship Series or LCS for short is an esports league where 10 professional teams compete against each other playing League of Legends. League of Legends is a multiplayer online battle arena game (or MOBA for short), played on the computer where teams of 5 players control their online avatars known as champions work together (or sometimes against each other)  to knock down the opposing team's nexus. Games last around 30 minutes on average. Additional reading here: 

https://en.wikipedia.org/wiki/League_of_Legends_Championship_Series

https://esportsedition.com/league-of-legends/a-beginners-guide-to-competitive-league-of-legends/

```{r setup, warning = FALSE, include= FALSE}
library(tidyverse)
library(kableExtra)
library(rvest)
library(broom)
library(ggrepel)
```

There are many ways we can obtain data, in this case, we will be scraping the data from a website. Oracleselixir.com is a website which hosts player and team statistics for the LCS as well as other leagues. We will scrape our data from this website using rvest. First, we must locate the data that we want on the page. By using chrome’s developer tools and looking through the page’s markdown, we can find the <table> element and get the table id. The table that holds statistics for the 2019 LCS spring split is identified as “tablepress-460”.  

![](/Users/blue/Downloads/findingthetable.png)

With the URL and table id we can use rvest to scrape the table and convert it into a data frame which we can manipulate through rstudio. Here we use read_html() to get our web page, html_node() to lock onto our table that we want, and html_table() and as.data.frame() to turn the table into a data frame. The code that achieves this is shown below:

```{r, warning = FALSE}
library(rvest)

url1 <- "https://oracleselixir.com/statistics/na/lcs-2019-spring-regular-season-player-statistics/"

spring_2019_tab <- read_html(url1) %>%
  html_node("#tablepress-460")%>%
  html_table() %>% as.data.frame()


kable(spring_2019_tab  %>% head(5), "html") %>%
  kable_styling(latex_options = "scale_down", font_size = 8)
```

We repeat this process for 3 additional tables making 3 more dataframes:

```{r warning = FALSE}
url2 <- "https://oracleselixir.com/statistics/na/na-lcs-2018-summer-regular-season-player-statistics/"

summer_2018_tab <- read_html(url2) %>%
  html_node("#tablepress-408")%>%
  html_table() %>% as.data.frame()

url3 <- "https://oracleselixir.com/statistics/na/na-lcs-2018-spring-regular-season-player-statistics/"

spring_2018_tab <- read_html(url3) %>%
  html_node("#tablepress-370")%>%
  html_table() %>% as.data.frame()

url4 <- "https://oracleselixir.com/statistics/na/na-lcs-2017-summer-regular-season-player-statistics/"

summer_2017_tab <- read_html(url4) %>%
  html_node("#tablepress-307")%>%
  html_table() %>% as.data.frame()
```

Each data frame represents a different split. In the LCS, there are two splits per year: spring and summer. We want to combine these tables to get a more complete data set. However, if we were to do so, we would not be able to identify which entity comes from which split. We can fix this by creating additional columns which have the attributes: year and split. The code that achieves this is shown below:

```{r warning = FALSE}
spring_2019_tab$year <- 2019
spring_2019_tab$split <- "spring"

summer_2018_tab$year <- 2018
summer_2018_tab$split <- "summer"

spring_2018_tab$year <- 2018
spring_2018_tab$split <- "spring"

summer_2017_tab$year <- 2017
summer_2017_tab$split <- "summer"

kable(spring_2019_tab  %>% head(5), "html") %>%
  kable_styling(latex_options = "scale_down", font_size = 8)
```

We can then combine the data frames into a singular dataframe using rbind():

```{r warning = FALSE}
lcs_tab <- rbind(spring_2019_tab, summer_2018_tab, spring_2018_tab, summer_2017_tab)
lcs_tab <- lcs_tab %>% filter(GP > 5)

kable(lcs_tab  %>% head(5), "html") %>%
  kable_styling(latex_options = "scale_down", font_size = 8)
```

Some of the meaningful variables such as win percent, damage share, and gold share are stored as char type variables. We need to change them into continuous numeric attributes so that we can use them for our calculations. First, we remove the "%" character from each data entry using gsub:

```{r warning = FALSE}
lcs_tab$`W%` <- gsub("%", "", lcs_tab$`W%`)
lcs_tab$KP <- gsub("%", "", lcs_tab$KP)
lcs_tab$`DTH%` <- gsub("%", "", lcs_tab$`DTH%`)
lcs_tab$`FB%` <- gsub("%", "", lcs_tab$`FB%`)
lcs_tab$`CS%P15` <- gsub("%", "", lcs_tab$`CS%P15`)
lcs_tab$`DMG%` <- gsub("%", "", lcs_tab$`DMG%`)
lcs_tab$`Gold%` <- gsub("%", "", lcs_tab$`Gold%`)

kable(lcs_tab  %>% head(), "html") %>%
  kable_styling(latex_options = "scale_down", font_size = 8)
```

Then we parse them into double type attributes and divide them by 100 to get them into a range between 0 and 1. We give them more meaningful names. For example, DMG% (damage percent) is the damage a player does in proportion to the rest of their team, so their share of their team's damage, rather than the total damage from both teams:

```{r warning = FALSE}                            
lcs_tab$`W%` <- (parse_double(lcs_tab$`W%`) / 100.0)
lcs_tab$KP <- (parse_double(lcs_tab$KP) / 100.0)
lcs_tab$`DTH%` <- (parse_double(lcs_tab$`DTH%`) / 100.0)
lcs_tab$`FB%` <- (parse_double(lcs_tab$`FB%`) / 100.0)
lcs_tab$`CS%P15` <- (parse_double(lcs_tab$`CS%P15`) / 100.0)
lcs_tab$`DMG%` <- (parse_double(lcs_tab$`DMG%`) / 100.0)
lcs_tab$`Gold%` <- (parse_double(lcs_tab$`Gold%`) / 100.0)

colnames(lcs_tab)[colnames(lcs_tab)=="W%"] <- "win_p"
colnames(lcs_tab)[colnames(lcs_tab)=="DTH%"] <- "death_share"
colnames(lcs_tab)[colnames(lcs_tab)=="FB%"] <- "fb_p"
colnames(lcs_tab)[colnames(lcs_tab)=="CS%P15"] <- "cs_share_pre15"
colnames(lcs_tab)[colnames(lcs_tab)=="DMG%"] <- "damage_share"
colnames(lcs_tab)[colnames(lcs_tab)=="Gold%"] <- "gold_share"

kable(lcs_tab  %>% head(5), "html") %>%
  kable_styling(latex_options = "scale_down", font_size = 8)
```

For the next part of the tutorial, we will be performing an analysis on a portion of the data we have collected. We want to perform an analysis on player stats during the spring split of 2019, the most recent split. By using the filter() function we can form a new data frame that only has rows with the desired attributes. The code below does this by only selecting the rows where the year attribute equals 2019, the split attribute equals spring and the GP (games played) attribute is greater than 5:

```{r warning = FALSE}
plot_tab <- lcs_tab %>% 
  filter(year == 2019, split == "spring", GP > 5) %>%
  group_by(Player)
```

In League of Legends (or LoL) for short, one metric in which people measure player performance is damage dealt. Many use this statistic to evaluate a players contribution to the game. In the data set we created, there are several statistics that evaluate damage. The one we will be using is damage_share. This stat is the percentage of the team's total damage dealt by an individual player. Other damage stats such as DPM (damage per minute) are heavily influenced by game length as the longer a game lasts the higher the damage per minute. There is a common consensus in the LoL community that gold is a statistic that is positively correlated with damage. We would like to see if this assumption is valid. Like damage, there are several stats that evaluate the gold a player has. The one we will be using is gold_share the proportion of the teams gold a player has. Like damage_share, it is not as heavily influenced by other factors. Furthermore, in professional games, gold can be distributed amongst players to an extent, so by comparing damage_share to gold_share, we can determine a players contribution to a game relative to the resources given to them. As such, it might be incorrect to evaluate players solely on damage share. A better assessment might involve "damage share based upon gold share". One way we can learn more about the relationship amongst attributes is by creating a plot. We can create a scatter plot that shows the relationship between damage_share and gold_share. ggplot allows us to build plots with relative ease. Further reading on ggplot here:

https://ggplot2.tidyverse.org/reference/

Below is the code that makes a scatter plot with damage_share on the y-axis and gold_share on the x-axis. Furthermore, we label each point by setting the label parameter equal to the player attribute. By using geom_text_repel() from the library ggrepel we can label the player name of each point without too much cluttering:

```{r warning = FALSE}
library(ggrepel)

ggplot(plot_tab, aes(x = gold_share, y = damage_share, group = Pos, label = Player)) +
  geom_jitter() +
  labs(title ="Damage Share vs Gold Share", x = "Gold Share", y = "Damage Share") + 
  geom_text_repel(color = "Orange")
```

By observing the plot we have just created, we can learn more about the data. There appears to be a positive correlation between damage share and gold share which goes to support our initial assumtion about the relationship betweeen damage_share and gold_share. Furthermore, there appears to be three distinct clusters which seem to correlate with the players' positions (these positions are similar to the roles of players in traditional sports such as first base, second base, and pitcher in baseball or offenseive line, linebacker, and runningback in football). There are five positions in League of Legends. The bottom cluster consists of supports and the middle cluster consists of junglers, but the top right cluster is an ambiguous mix of top, mid, and adc players. We can add colors to the graph based on each players role to make these clusters more defined by setting the group and color parameters equal to Pos which is position:

```{r}
ggplot(plot_tab, aes(x = gold_share, y = damage_share, group = Pos, label = Player)) +
  geom_jitter(aes(color = Pos)) +
  labs(title ="Damage Share vs Gold Share", x = "Gold Share", y = "Damage Share") + 
  geom_text_repel(aes(color = Pos))
```

These clusters based on the player's position may require further investigation.

After observing these plots, we can see a definite relationship between gold_share and damage_share. One question we may have is: given players a gold_share, what should we expect the damage_share to be? One way we can answer this question is with a linear regression. A linear regression will allow us to analyze the relationship between a continuous numerical variable Y and another variable x. Further reading on linear regressions:

https://en.wikipedia.org/wiki/Linear_regression


We will be using the lm() function to perform a linear regression and create a linear model that gives us an expected damage_share as a function of gold_share. By using tidy() we can then turn the model into a data frame and use it for further analysis. The code that achieves this is below:

```{r warning = FALSE}
library(broom)
eff_fit <- lm(damage_share~gold_share, data=plot_tab)

eff_fit_stats <- eff_fit %>%
  tidy()

eff_fit_stats 
```

The data frame we are given has estimates for both the intercept and the parameter gold_share. Using the intercept and the parameter we can create a function to predict damage_share given a gold_share. The gold_shares value 1.5070441 can be interpreted as follows: On average, for every unit of gold_share, damage_share increases by 1.5070441. And the intercept -0.1017227    can be interpreted as the damage_share when gold_share is 0 (however we can actually have negative damage). On the far right of the table, there is an attribute p.value which tells us the probability that the null hypothesis is true given the data. In this case, the null hypothesis is "there is no relationship between gold_share and damage_share." Since the p-value, in this case, is extremely low (5.543648e-26), we can reject the null hypothesis. More on hypothesis testing here:

http://mathworld.wolfram.com/HypothesisTesting.html

We can use this model to help us answer the question: given a players gold_share, does the player have a higher or lower damage_share than expected? In other words, how efficient is a player? Using the mutate() function we can create a new attribute called efficiency. efficiency, in this case, will be the difference between a player's actual damage_share and predicted damage_share using the linear model we created. The code that achieves this is below:

```{r warning = FALSE}
plot_tab <- plot_tab %>% 
  mutate(expected_damage_share = eff_fit$coefficients[1]+ (eff_fit$coefficients[2] * gold_share)) %>%
  mutate(efficiency = damage_share - expected_damage_share) 

kable(plot_tab  %>% head(5), "html") %>%
  kable_styling(latex_options = "scale_down", font_size = 8)
```

We can then use ggplot create a bar plot the top 10 most efficient and bottom 10 least efficient players to observe the data. The code that achieves this is below:

```{r warning = FALSE}
plot_tab$Player <- factor(plot_tab$Player, levels = plot_tab$Player[order(-plot_tab$efficiency)])

most_eff <- plot_tab %>% arrange(desc(efficiency)) %>% head(10)


ggplot(most_eff, aes(x = Player, y = efficiency, group = Pos)) +
  geom_bar(aes(fill = Pos, drop = FALSE), stat = "identity") +
  labs(title ="Top 10 Most Efficient Players", x = "Player", y = "Efficiency")

least_eff <- plot_tab %>% arrange(efficiency) %>% head(10)

ggplot(least_eff, aes(x = Player, y = efficiency)) +
  geom_bar(aes(fill = Pos, drop = FALSE), stat = "identity") +
  labs(title ="Top 10 Least Efficient Players", x = "Player", y = "Efficiency")
```

We can observe that 5 of the 10 most efficient players play the Middle position with the most efficient player being Froggen. When we created our first 2 scatter plots, we observed that there seemed to be some relation between player position, gold_share, and damage_share. We can then use ggplot to plot the mean gold_share, damage_share, and efficiency based upon position to get a better grasp of the data. First, we want to use the group_by() function to group by position. Then we want to use the summarize function in order to calculate the mean gold_share, damage_share, and efficiency for each position. The code which achieves this is below:

```{r warning = FALSE}
pos_tab <- plot_tab %>% group_by(Pos) %>% summarize(mean_gold_share=mean(gold_share), mean_damage_share=mean(damage_share)) 

ggplot(pos_tab, aes(x = Pos, y = mean_gold_share)) +
  geom_bar(aes(fill = Pos), stat = "identity") +
  labs(title ="Mean Gold Share by Position", x = "Position", y = "Mean Gold Share")

ggplot(pos_tab, aes(x = Pos, y = mean_damage_share)) +
  geom_bar(aes(fill = Pos), stat = "identity") +
  labs(title ="Mean Damage Share by Position", x = "Position", y = "Mean Gold Share") 

pos_tab <- plot_tab %>% group_by(Pos) %>% summarize(mean_efficiency=mean(efficiency)) 

ggplot(pos_tab, aes(x = Pos, y = mean_efficiency)) +
  geom_bar(aes(fill = Pos),stat = "identity") +
  labs(title ="Mean Efficiency by Position", x = "Position", y = "Mean Efficiency") 
```

We can observe that there is a clear difference amongst the positions in regards to average gold_share, damage_share, and efficiency. Each position has different responsibilities in the team and plays different characters so comparing results between different positions gives us some skewed results. However, we can fix this by standardizing by position. By standardizing gold_share and damage_share by position we can compare efficiency by position with less skewed results. After grouping by position, we can standardize an attribute by taking the difference between the attribute of the entity and the mean of that attribute and dividing it by the standard deviation of that attribute. More on standardization here:

https://stats.idre.ucla.edu/stata/faq/how-do-i-standardize-variables-in-stata/

The code that achieves this is below:

```{r warning = FALSE}
plot_tab <- lcs_tab %>% 
  filter(year == 2019, split == "spring", GP > 5) %>%
  group_by(Player)

plot_tab <- plot_tab %>%
  group_by(Pos) %>%
  mutate(standard_gold_share = (gold_share - mean(gold_share)) / sd(gold_share))

plot_tab <- plot_tab %>%
  group_by(Pos) %>%
  mutate(standard_damage_share = (damage_share - mean(damage_share)) / sd(damage_share))

kable(plot_tab  %>% head(5), "html") %>%
  kable_styling(latex_options = "scale_down", font_size = 8)
```

We can now do a scatter plot with standardized variables and observe the results:

```{r warning = FALSE}
ggplot(plot_tab, aes(x = standard_gold_share, y = standard_damage_share, label = Player)) +
  geom_jitter(aes(color = Pos)) +
  labs(title ="Standardized Damage Share vs Standardized Gold Share", x = "Standardized Gold Share", y = "Standardized Damage Share") + 
  geom_text_repel(aes(color = Pos))
```

The plot no longer has the position clusters as we had in the first two scatter plots so we can assume standardizing helped by comparing a player's stats in regards to their position average. Let us see if this changes efficiency by performing another linear regression and re-calculating efficiency using standardized variables:

```{r warning = FALSE}
eff_fit <- lm(standard_damage_share~standard_gold_share, data=plot_tab)

plot_tab <- plot_tab %>% 
  mutate(standard_expected_damage_share = eff_fit$coefficients[1]+ (eff_fit$coefficients[2] * standard_gold_share)) %>%
  mutate(standard_efficiency = standard_damage_share - standard_expected_damage_share) 

kable(plot_tab  %>% head(5), "html") %>%
  kable_styling(latex_options = "scale_down", font_size = 8)
```

Now let us plot the top 10 most efficient and bottom 10 least efficient players and see if standardization did anything:

```{r warning = FALSE}
plot_tab$Player <- factor(plot_tab$Player, levels = plot_tab$Player[order(-plot_tab$standard_efficiency)])

most_eff <- plot_tab %>% arrange(desc(standard_efficiency)) %>% head(10)


ggplot(most_eff, aes(x = Player, y = standard_efficiency)) +
  geom_bar(aes(fill = Pos), stat = "identity") +
  labs(title ="Top 10 Most Efficient Players (Standardized)", x = "Player", y = "Standard Efficiency") 

least_eff <- plot_tab %>% arrange(standard_efficiency) %>% head(10)

ggplot(least_eff, aes(x = Player, y = standard_efficiency)) +
  geom_bar(aes(fill = Pos), stat = "identity") +
  labs(title ="Top 10 Least Efficient Players (Standardized)", x = "Player", y = "Standard Efficiency") 
```

The difference is night and day as players who play the Middle position no longer dominate the top 10 most efficient players plot. Froggen is now the 3rd most efficient player with the new most efficient player being Huni. And thus concludes this walkthrough.